# DOF-RAG

**DOF-RAG** es un sistema de consulta por generaci√≥n aumentada (RAG) para explorar las ediciones del Diario Oficial de la Federaci√≥n de M√©xico usando tecnolog√≠as de inteligencia artificial modernas.

## Caracter√≠sticas Principales

- **M√∫ltiples formatos**: Soporte para archivos PDF y WORD del DOF
- **Extracci√≥n completa**: Incluye documentos principales, avisos y convocatorias
- **Procesamiento unificado**: Convierte y unifica m√∫ltiples archivos DOC en documentos DOCX √∫nicos
- **Conversi√≥n inteligente**: Usa Pandoc con filtros LUA para conversi√≥n DOCX ‚Üí Markdown
- **Embeddings avanzados**: Sistema con modelo Qwen3-Embedding-0.6B y almacenamiento en DuckDB
- **Chunking sem√°ntico**: Divisiones inteligentes respetando estructura de documentos
- **Procesamiento optimizado**: Soporte para GPU (CUDA), Apple Silicon (MPS) y CPU

## Requisitos

### Dependencias Python

Instala [uv](https://docs.astral.sh/uv/) para manejar las dependencias de Python:

```bash
uv venv # Crear entorno virtual
uv sync # Sincronizar dependencias
```

### Herramientas Externas

- **LibreOffice**: Para conversi√≥n DOC ‚Üí DOCX
- **Pandoc**: Para conversi√≥n DOCX ‚Üí Markdown

```bash
# Ubuntu/Debian
sudo apt install libreoffice pandoc

# macOS
brew install --cask libreoffice
brew install pandoc
```

## Flujo de Trabajo Principal

El sistema DOF-RAG utiliza un **√∫nico flujo principal** optimizado para procesamiento completo de documentos del DOF:

### **Flujo Completo: WORD ‚Üí DOCX ‚Üí Markdown ‚Üí Embeddings**

#### 1. Descarga de Archivos WORD + Avisos
```bash
# Descargar archivos WORD de una fecha espec√≠fica (incluye avisos y convocatorias)
uv run get_word_dof.py 02/01/2025 --editions both

# Descargar un rango de fechas
uv run get_word_dof.py 01/01/2025 31/01/2025 --editions both --sleep-delay 1.0

# Solo edici√≥n matutina
uv run get_word_dof.py 02/01/2025 --editions mat
```

**Estructura generada:**
```
dof_word/
‚îú‚îÄ‚îÄ 2025/
‚îÇ   ‚îú‚îÄ‚îÄ 01/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02012025/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MAT/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 001_DOF_20250102_MAT_12345.doc
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 002_AVISO_20250102_MAT_67890.doc
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 003_DOF_20250102_MAT_11111.doc
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ VES/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ 001_DOF_20250102_VES_22222.doc
```

#### 2. Conversi√≥n DOC ‚Üí DOCX + Unificaci√≥n
```bash
# Procesar una fecha espec√≠fica (convierte y unifica autom√°ticamente)
uv run dof_processor.py 02/01/2025

# Procesar un rango de fechas
uv run dof_processor.py 01/01/2025 31/01/2025 --input-dir ./dof_word

# Con logging detallado
uv run dof_processor.py 02/01/2025 --log-level DEBUG
```

**Estructura generada:**
```
dof_docx/
‚îú‚îÄ‚îÄ 2025/
‚îÇ   ‚îú‚îÄ‚îÄ 01/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02012025/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MAT/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 02012025_MAT.docx  # ‚Üê Archivo unificado
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ VES/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ 02012025_VES.docx  # ‚Üê Archivo unificado
```

#### 3. Conversi√≥n DOCX ‚Üí Markdown (Sin Paginaci√≥n)

> **‚ö†Ô∏è Nota sobre Paginaci√≥n y Herramientas:**
> 
> La paginaci√≥n original de los documentos DOF **solo se puede preservar usando Microsoft Word**. En entornos Linux o usando LibreOffice + Pandoc, se pierde la informaci√≥n de p√°ginas durante la conversi√≥n. Por esta raz√≥n, nuestros flujos de trabajo se centran en **procesamiento de contenido sin paginaci√≥n**, optimizado para embeddings y b√∫squeda sem√°ntica.
> 
> **Comparaci√≥n con herramientas anteriores:**
> - **LibreOffice + Pandoc:** No preserva saltos de p√°gina pero **mucho m√°s r√°pido** que marker-pdf
> - **marker-pdf (herramienta anterior):** Ten√≠a problemas graves con documentos DOF:
>   - Calidad deficiente en encabezados
>   - P√©rdida de palabras en tablas complejas  
>   - Generaci√≥n de tablas corruptas con etiquetas `<br>` no v√°lidas
>   - Rendimiento significativamente m√°s lento
> - **Ventaja actual:** Contenido optimizado, procesamiento m√°s r√°pido y sin corrupci√≥n

```bash
# Convertir archivos DOCX espec√≠ficos usando Pandoc
uv run dof_docx_to_md.py 02/01/2025

# Convertir un rango de fechas
uv run dof_docx_to_md.py 01/01/2025 31/01/2025

# Procesar todos los archivos DOCX disponibles
uv run dof_docx_to_md.py

# Con directorio personalizado
uv run dof_docx_to_md.py --input-dir ./dof_docx --output-dir ./dof_word_md_custom
```

**Estructura generada:**
```
dof_word_md/
‚îú‚îÄ‚îÄ 2025/
‚îÇ   ‚îú‚îÄ‚îÄ 01/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02012025/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MAT/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02012025_MAT.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ media_temp/             # ‚Üê Im√°genes extra√≠das
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ VES/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ 02012025_VES.md
```

#### 4. Generaci√≥n de Embeddings (Optimizado para Markdown sin Paginaci√≥n)
```bash
# Procesar archivos Markdown generados
uv run extract_embeddings.py dof_word_md/2025/ --verbose

# Con control de memoria
uv run extract_embeddings.py dof_word_md/2025/ --memory-cleanup-interval 25

# Procesar un mes espec√≠fico
uv run extract_embeddings.py dof_word_md/2025/01/ --verbose
```

---

## Flujo Alternativo: Solo PDFs (Limitado)

**Nota**: `get_dof.py` solo descarga PDFs del DOF (edici√≥n matutina √∫nicamente). **No hay procesamiento autom√°tico posterior** - los PDFs requieren procesamiento manual adicional para generar embeddings.

#### Descarga de PDFs
```bash
# Descargar PDFs desde 2025 hacia atr√°s hasta 2024 (el script cuenta hacia atr√°s)
uv run get_dof.py --start-year=2025 --end-year=2024

# Descargar un rango espec√≠fico (desde 2025 hacia atr√°s hasta 2020)
uv run get_dof.py --start-year=2025 --end-year=2020
```

**Estructura generada:**
```
dof/
‚îú‚îÄ‚îÄ 2025/
‚îÇ   ‚îú‚îÄ‚îÄ 01/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02012025-MAT.pdf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03012025-MAT.pdf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
```

**‚ö†Ô∏è Limitaciones del flujo PDF:**
- Solo edici√≥n matutina
- No incluye avisos ni convocatorias  
- Requiere procesamiento manual adicional
- No est√° integrado con el sistema de embeddings

---

## üìö Cobertura Hist√≥rica del DOF

### **Per√≠odos Disponibles:**

#### **1999 - Actualidad**: Documentos Digitales (WORD/DOC)
- **Formato**: Archivos DOC descargables
- **Contenido**: Documentos principales + avisos + convocatorias
- **Ediciones**: Matutina y Vespertina
- **Procesamiento**: Flujo principal optimizado (DOC ‚Üí DOCX ‚Üí MD ‚Üí Embeddings)

#### **1920 - 1999**: Documentos Escaneados (PDF √∫nicamente)
- **Formato**: Solo PDFs (documentos escaneados)
- **Contenido**: Documentos principales escaneados
- **Procesamiento**: Requiere herramientas de OCR adicionales
- **Estado**: Disponible para descarga, requiere procesamiento especializado

### **Pr√≥ximos Desarrollos:**
- Sistema de consultas y b√∫squeda sem√°ntica
- Procesamiento OCR para documentos hist√≥ricos (1920-1999)
- Interfaz de usuario para consultas
- API de b√∫squeda y recuperaci√≥n

## Uso del Sistema

### Sistema de Embeddings

Una vez procesados los archivos Markdown, el sistema genera embeddings y los almacena en una base de datos DuckDB.

**Base de Datos:** `dof_db/db.duckdb`

### ¬øC√≥mo Verificar la Base de Datos?

Puedes inspeccionar la base de datos generada para verificar que los documentos y chunks se han guardado correctamente. Para ello, puedes usar el cliente de l√≠nea de comandos de DuckDB.

1.  **Instala DuckDB** (si no lo tienes, aunque deber√≠a estar incluido en las dependencias del proyecto):
    ```bash
    pip install duckdb
    ```

2.  **Abre la base de datos**:
    ```bash
    duckdb dof_db/db.duckdb
    ```

3.  **Ejecuta consultas SQL para explorar los datos**:

    *   **Contar el n√∫mero total de documentos procesados**:
        ```sql
        SELECT COUNT(*) FROM documents;
        ```

    *   **Ver los 5 documentos m√°s recientes**:
        ```sql
        SELECT * FROM documents ORDER BY created_at DESC LIMIT 5;
        ```

    *   **Contar el n√∫mero total de chunks generados**:
        ```sql
        SELECT COUNT(*) FROM chunks;
        ```

    *   **Ver un chunk espec√≠fico y su texto asociado**:
        ```sql
        SELECT id, document_id, header, chunk_number, text FROM chunks LIMIT 1;
        ```

    *   **Encontrar todos los chunks de un documento espec√≠fico (ej. ID=10)**:
        ```sql
        SELECT chunk_number, header, text FROM chunks WHERE document_id = 10 ORDER BY chunk_number;
        ```

**Nota**: El sistema de consultas sem√°nticas est√° en desarrollo. Los embeddings se generan y almacenan correctamente en la base de datos DuckDB para su uso posterior en futuras funcionalidades.

## Estructura del Proyecto

```
dof-rag/
‚îú‚îÄ‚îÄ Scripts principales
‚îÇ   ‚îú‚îÄ‚îÄ get_dof.py              # Descarga PDFs del DOF (sin procesamiento posterior)
‚îÇ   ‚îú‚îÄ‚îÄ get_word_dof.py         # Descarga archivos WORD + avisos/convocatorias
‚îÇ   ‚îú‚îÄ‚îÄ dof_processor.py        # Convierte DOC ‚Üí DOCX + unifica
‚îÇ   ‚îú‚îÄ‚îÄ dof_docx_to_md.py       # Convierte DOCX ‚Üí Markdown (Pandoc + filtros LUA)
‚îÇ   ‚îî‚îÄ‚îÄ extract_embeddings.py   # Sistema de embeddings (procesa Markdown sin paginaci√≥n)
‚îú‚îÄ‚îÄ Datos - Flujo Principal (WORD)
‚îÇ   ‚îú‚îÄ‚îÄ dof_word/              # Archivos DOC + avisos descargados
‚îÇ   ‚îú‚îÄ‚îÄ dof_docx/              # Archivos DOCX unificados  
‚îÇ   ‚îú‚îÄ‚îÄ dof_word_md/           # Markdown optimizado (sin paginaci√≥n)
‚îÇ   ‚îî‚îÄ‚îÄ dof_db/                # Base de datos DuckDB con embeddings
‚îú‚îÄ‚îÄ Datos - Alternativo (PDF)
‚îÇ   ‚îî‚îÄ‚îÄ dof/                   # PDFs descargados (requiere procesamiento manual)
‚îú‚îÄ‚îÄ Herramientas
‚îÇ   ‚îú‚îÄ‚îÄ pandoc_filters/         # Filtros LUA para Pandoc
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dof_headers.lua    # Filtro para headers del DOF
‚îÇ   ‚îî‚îÄ‚îÄ modules_captions/       # M√≥dulos de extracci√≥n de metadatos
‚îî‚îÄ‚îÄ Configuraci√≥n
    ‚îî‚îÄ‚îÄ pyproject.toml          # Dependencias del proyecto
```

## Caracter√≠sticas T√©cnicas

### Limitaciones de Paginaci√≥n
> **Importante:** El sistema est√° dise√±ado para **contenido continuo sin paginaci√≥n** debido a limitaciones t√©cnicas de las herramientas open-source:
> 
> - **Microsoft Word**: √önica herramienta que preserva paginaci√≥n original
> - **LibreOffice + Pandoc**: Pierden informaci√≥n de saltos de p√°gina
> - **Enfoque del sistema**: Optimizado para b√∫squeda sem√°ntica y embeddings
> - **Ventaja**: Chunking m√°s efectivo sin interrupciones artificiales de p√°gina

### Decisiones Arquitect√≥nicas: Migraci√≥n de marker-pdf
> **Cambio tecnol√≥gico documentado:** Se migr√≥ de `marker-pdf` al flujo actual por problemas cr√≠ticos de calidad:
> 
> **Problemas con marker-pdf:**
> - ‚ùå Encabezados mal procesados o perdidos
> - ‚ùå P√©rdida de palabras en tablas complejas
> - ‚ùå Tablas corruptas con etiquetas `<br>` inv√°lidas
> - ‚ùå Rendimiento lento para documentos extensos
> 
> **Ventajas del flujo actual (LibreOffice + Pandoc):**
> - ‚úÖ **Velocidad significativamente superior**
> - ‚úÖ Preservaci√≥n completa de encabezados
> - ‚úÖ Tablas bien formateadas sin corrupci√≥n
> - ‚úÖ Contenido limpio optimizado para embeddings

### Modelo de Embeddings: Qwen3-Embedding-0.6B

Este proyecto utiliza [Qwen/Qwen3-Embedding-0.6B](https://huggingface.co/Qwen/Qwen3-Embedding-0.6B), un modelo de embeddings de texto optimizado para tareas de Recuperaci√≥n de Informaci√≥n (RAG). A continuaci√≥n se detallan sus caracter√≠sticas principales:

-   **Tama√±o y Arquitectura**: Es un modelo basado en Transformers con **0.6 mil millones de par√°metros**, lo que ofrece un excelente equilibrio entre rendimiento y eficiencia computacional.
-   **Longitud de Secuencia**: Soporta una longitud m√°xima de contexto de **32k tokens**, permitiendo procesar documentos extensos sin necesidad de truncarlos excesivamente.
-   **Dimensiones del Embedding**: Genera embeddings con una dimensi√≥n de **1024**, capturando una gran riqueza sem√°ntica.
-   **Modelo Matrioska (Matryoshka Representation)**: Este modelo implementa una t√©cnica que permite que los embeddings generados sean efectivos incluso si se truncan a dimensiones m√°s peque√±as (ej. 512, 256). Esto ofrece flexibilidad para adaptar el tama√±o del embedding a los requisitos de almacenamiento o rendimiento sin necesidad de reentrenar.
-   **Last Token Pooling**: En lugar de promediar todos los tokens de la secuencia (mean pooling), el modelo utiliza la representaci√≥n del √∫ltimo token como el embedding final para todo el texto. Esta estrategia est√° alineada con su entrenamiento y ha demostrado ser altamente efectiva.
-   **Uso de Instrucciones**: Para mejorar la relevancia en tareas de b√∫squeda, el modelo utiliza prefijos espec√≠ficos (instrucciones) para diferenciar entre la codificaci√≥n de pasajes (documentos) y la codificaci√≥n de consultas (preguntas). Por ejemplo:
    -   **Para documentos (instruct)**: Se a√±ade un prefijo que indica al modelo que genere una representaci√≥n para ser almacenada y encontrada.
    -   **Para b√∫squedas (question)**: Se utiliza un prefijo diferente para indicar que el texto es una consulta, optimizando el embedding para la tarea de b√∫squeda.

    **Ejemplo de formato en c√≥digo:**
    ```python
      # 1. Definir la tarea de recuperaci√≥n
      task_description = "Retrieve relevant legal document fragments including text, image descriptions, and table content that match the query"

      # 2. Formatear la consulta con la instrucci√≥n
      user_query = "..." # Pregunta del usuario
      instructed_query = f'Instruct: {task_description}\nQuery: {user_query}'

      # 3. Generar el embedding (ejemplo conceptual de la implementaci√≥n interna)
      with inference_mode():
          embedding = embedding_model.encode([instructed_query], show_progress_bar=False)
    ```

### Modelos y Tecnolog√≠as
- **Pandoc + Filtros LUA**: Conversi√≥n DOCX ‚Üí Markdown sin paginaci√≥n
- **LibreOffice**: Conversi√≥n DOC ‚Üí DOCX en modo headless
- **Qwen3-Embedding-0.6B**: Generaci√≥n de embeddings (1024 dimensiones)
- **DuckDB**: Almacenamiento de embeddings con FLOAT[] arrays
- **MarkdownSplitter**: Chunking sem√°ntico optimizado para Markdown unificado

### Optimizaciones
- **Soporte multi-plataforma**: CUDA, MPS (Apple Silicon), CPU
- **Gesti√≥n de memoria**: Limpieza autom√°tica cada N chunks
- **Chunking inteligente**: Preserva jerarqu√≠a de headers
- **Timeouts configurables**: Manejo robusto de archivos problem√°ticos (90s LibreOffice)
- **Unificaci√≥n autom√°tica**: M√∫ltiples DOCs ‚Üí 1 DOCX por edici√≥n/fecha
- **Extracci√≥n de medios**: Im√°genes y tablas preservadas en conversi√≥n

### Base de Datos
```sql
-- Estructura de tablas en DuckDB
documents (id, title, url, file_path, created_at)
chunks (id, document_id, text, header, chunk_number, embedding[1024], created_at)
```

## üö® Notas Importantes

### Dependencias Cr√≠ticas
- **LibreOffice**: Necesario para conversi√≥n DOC ‚Üí DOCX 
  ```bash
  # Ubuntu/Debian
  sudo apt install libreoffice
  
  # macOS  
  brew install --cask libreoffice
  ```
- **Pandoc**: Necesario para conversi√≥n DOCX ‚Üí Markdown
  ```bash
  # Ubuntu/Debian
  sudo apt install pandoc
  
  # macOS
  brew install pandoc
  ```

### Consideraciones de Rendimiento
- **Memoria**: Los embeddings pueden requerir significativa RAM para datasets grandes
- **Timeouts**: LibreOffice tiene timeout de 90s por archivo DOC
- **Archivos problem√°ticos**: Se generan reportes autom√°ticos de archivos que fallan por timeout
- **Limpieza autom√°tica**: Se eliminan archivos temporales tras unificaci√≥n

## Logs y Debugging

El sistema genera logs detallados:
- `dof_processing.log`: Logs del sistema principal de embeddings y extracci√≥n
- `dof_processor.log`: Logs de conversi√≥n DOC/DOCX  
- `convert_docx_to_md.log`: Logs de conversi√≥n DOCX/Markdown
- `word_download.log`: Logs de descarga de archivos WORD
- `archivos_problematicos_*.txt`: Reportes de archivos con timeout

Para debugging detallado, usa el flag `--verbose` o `--log-level DEBUG` en los scripts compatibles.

## üîÑ Arquitectura del Sistema

### **Flujo Principal Optimizado** 
El sistema est√° dise√±ado espec√≠ficamente para el procesamiento completo de documentos del DOF:

```
DOC + Avisos ‚Üí DOCX Unificado ‚Üí Markdown Sin Paginaci√≥n ‚Üí Embeddings Optimizados
```

### **Caracter√≠sticas Clave:**
- **Unificaci√≥n**: M√∫ltiples archivos DOC se consolidan en un DOCX por fecha/edici√≥n
- **Sin Paginaci√≥n**: El Markdown generado no tiene separaciones de p√°gina (optimizado para embeddings)
- **Estructura Sem√°ntica**: Preserva jerarqu√≠a de headers y estructura de documentos
- **Contenido Completo**: Incluye documentos principales + avisos + convocatorias

### **Flujo Alternativo (Limitado):**
- `get_dof.py` descarga PDFs pero no est√° integrado con el sistema de embeddings
- Requiere procesamiento manual adicional para generar embeddings

## üìà Rendimiento y Caracter√≠sticas

### Tiempos de Procesamiento

Los tiempos de procesamiento var√≠an seg√∫n el hardware y tama√±o de los archivos. Como referencia general:

#### Flujo Principal (WORD ‚Üí DOCX ‚Üí MD ‚Üí Embeddings):
- **Descarga**: Depende de la conexi√≥n de red y cantidad de archivos
- **DOC ‚Üí DOCX**: Variable seg√∫n tama√±o del archivo (timeout configurado a 90s)
- **Unificaci√≥n**: R√°pida, consolida m√∫ltiples archivos en uno
- **DOCX ‚Üí Markdown**: Variable seg√∫n complejidad del documento
- **Embeddings**: Depende del hardware (GPU/CPU) y longitud del texto

### Consideraciones de Hardware
- **M√≠nimo**: 8GB RAM, LibreOffice, Pandoc
- **Recomendado**: 16GB+ RAM, GPU compatible con CUDA/MPS
- **√ìptimo**: 32GB+ RAM, GPU dedicada, m√∫ltiples n√∫cleos CPU

## Casos de Uso y Recomendaciones

### **Para Documentos Actuales (1999-2025)**

#### Usa el **Flujo Principal** (WORD) para:
- ‚úÖ An√°lisis completo del DOF (documentos + avisos + convocatorias)
- ‚úÖ Ambas ediciones (matutina y vespertina)
- ‚úÖ Sistema de embeddings optimizado
- ‚úÖ Preservar formato e im√°genes originales
- ‚úÖ M√°xima completitud de datos

### **Para Documentos Hist√≥ricos (1920-1999)**

#### Usa `get_dof.py` (PDFs) para:
- Descargar PDFs escaneados para archivo hist√≥rico
- Procesamiento con herramientas OCR externas
- An√°lisis de documentos hist√≥ricos

**Nota**: Los documentos hist√≥ricos requieren procesamiento especializado con herramientas OCR para extraer texto.

## Gu√≠a de Inicio R√°pido

### **Documentos Actuales (1999-2025)** - Procesamiento Completo
```bash
# 1. Instalar dependencias
sudo apt install libreoffice pandoc  # Linux
brew install --cask libreoffice && brew install pandoc  # macOS

# 2. Descargar archivos WORD completos
uv run get_word_dof.py 01/01/2025 31/01/2025 --editions both

# 3. Convertir y unificar DOC ‚Üí DOCX
uv run dof_processor.py 01/01/2025 31/01/2025

# 4. Convertir DOCX ‚Üí Markdown (sin paginaci√≥n)
uv run dof_docx_to_md.py 01/01/2025 31/01/2025

# 5. Generar embeddings
uv run extract_embeddings.py dof_word_md/2025/ --verbose
```

### **Documentos Hist√≥ricos (1920-1999)** - Solo Descarga
```bash
# Descargar PDFs escaneados para archivo o procesamiento especializado
uv run get_dof.py --start-year=1995 --end-year=1990
```

**Nota**: Los documentos hist√≥ricos son PDFs escaneados que requieren herramientas OCR adicionales para procesamiento de texto.